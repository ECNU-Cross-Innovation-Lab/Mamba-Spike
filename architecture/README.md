# Mamba-Spike æ¶æ„å›¾è¯´æ˜

## ğŸ“Š å¦‚ä½•æŸ¥çœ‹æ¶æ„å›¾

### æ–¹æ³•1: åœ¨çº¿æŸ¥çœ‹ï¼ˆæ¨èï¼‰
1. è®¿é—® [draw.io](https://app.diagrams.net/)
2. ç‚¹å‡» "Open Existing Diagram"
3. ä¸Šä¼  `mamba_spike_architecture.drawio` æ–‡ä»¶
4. å³å¯æŸ¥çœ‹å’Œç¼–è¾‘

### æ–¹æ³•2: VS Codeæ’ä»¶
```bash
# å®‰è£…Draw.io Integrationæ’ä»¶
code --install-extension hediet.vscode-drawio

# ç›´æ¥åœ¨VS Codeä¸­æ‰“å¼€.drawioæ–‡ä»¶
```

### æ–¹æ³•3: æ¡Œé¢åº”ç”¨
1. ä¸‹è½½ [diagrams.net Desktop](https://github.com/jgraph/drawio-desktop/releases)
2. å®‰è£…åæ‰“å¼€ `.drawio` æ–‡ä»¶

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

### å®Œæ•´æµç¨‹

```
Event Input (DVS Camera)
    â†“
Spiking Front-End (LIF Neurons)
    â”œâ”€ Conv2d + LIF (32 channels)
    â”œâ”€ Conv2d + LIF (32 channels)
    â””â”€ Conv2d + LIF (64 channels)
    â†“
Sparse Spikes (B, T, 64, H', W')
    â†“
Interface Layer (Spike-to-Activation)
    â””â”€ Rate Coding + Temporal Smoothing
    â†“
Input Projection (Linear)
    â””â”€ spike_features â†’ 128
    â†“
Mamba Backbone (4 Layers)
    â”œâ”€ Mamba Block 1 (LayerNorm + SSM + Residual)
    â”œâ”€ Mamba Block 2
    â”œâ”€ Mamba Block 3
    â””â”€ Mamba Block 4
    â†“
Global Average Pooling (over time)
    â†“
Classification Head
    â”œâ”€ LayerNorm
    â””â”€ Linear (128 â†’ num_classes)
    â†“
Output Logits (B, num_classes)
```

## ğŸ“ æ¶æ„ç»†èŠ‚

### 1. Spiking Front-End

**è¾“å…¥**: `(B, T, C, H, W)` - Event frames
- B: Batch size
- T: Time steps
- C: Channels (2 for DVS: ON/OFF)
- H, W: Height, Width

**ç»“æ„**:
```python
Conv2d(2â†’32, kernel=3) + MaxPool2d(2) + LIF(Î²=0.9)
    â†“
Conv2d(32â†’32, kernel=3) + MaxPool2d(2) + LIF(Î²=0.9)
    â†“
Conv2d(32â†’64, kernel=3) + LIF(Î²=0.9)
```

**è¾“å‡º**: `(B, T, 64, H/4, W/4)` - Sparse spikes

**å…³é”®ç‰¹æ€§**:
- ğŸ”¥ LIFç¥ç»å…ƒ: ç”Ÿç‰©å­¦åˆç†çš„è„‰å†²æœºåˆ¶
- âš¡ äº‹ä»¶é©±åŠ¨: ä»…åœ¨å¿…è¦æ—¶äº§ç”Ÿè„‰å†²
- ğŸ’¾ ç¨€ç–æ€§: æ˜¾è‘—é™ä½è®¡ç®—å’Œå†…å­˜éœ€æ±‚

### 2. Interface Layer

**åŠŸèƒ½**: å°†ç¦»æ•£è„‰å†²è½¬æ¢ä¸ºè¿ç»­æ¿€æ´»

**æ–¹æ³•**:
```python
# Rate Coding
activations = spikes.view(B, T, -1)  # Flatten spatial

# Temporal Smoothing (Conv1d)
kernel = ones(features, 1, 5) / 5  # Moving average
activations = conv1d(activations, kernel, groups=features)
```

**è¾“å‡º**: `(B, T, 64Ã—H'Ã—W')` - Continuous activations

### 3. Mamba Backbone

**æ ¸å¿ƒç»„ä»¶**: Selective SSM (State Space Model)

```python
class SelectiveSSM:
    def forward(x):
        # 1. Input projection
        x_proj = in_proj(x)  # Split into x and residual

        # 2. Convolution (local context)
        x = conv1d(x, kernel=4)

        # 3. State Space Model
        A = -exp(A_log)  # State transition
        dt, B, C = compute_parameters(x)  # Data-dependent!

        # 4. Selective Scan
        for i in range(L):
            h[i] = exp(dt[i]*A) * h[i-1] + dt[i]*B[i]*x[i]
            y[i] = C[i] * h[i] + D * x[i]

        # 5. Gated MLP
        y = y * silu(residual)

        return out_proj(y)
```

**å…³é”®åˆ›æ–°**:
- ğŸ¯ **é€‰æ‹©æ€§**: å‚æ•°dt, B, Cä¾èµ–äºè¾“å…¥
- âš¡ **çº¿æ€§å¤æ‚åº¦**: O(L) vs Transformerçš„O(LÂ²)
- ğŸ§  **é•¿ç¨‹ä¾èµ–**: æœ‰æ•ˆå»ºæ¨¡é•¿åºåˆ—

**æ¯ä¸ªMamba Block**:
```python
MambaBlock(x):
    return x + SSM(LayerNorm(x))  # Residual connection
```

### 4. Classification Head

```python
# Global pooling
x = x.mean(dim=1)  # (B, T, 128) â†’ (B, 128)

# Normalization + Classification
x = LayerNorm(x)
logits = Linear(x)  # (B, 128) â†’ (B, num_classes)
```

## ğŸ“Š å‚æ•°ç»Ÿè®¡

### æ¨¡å‹å¤§å°

| ç»„ä»¶ | å‚æ•°é‡ | å æ¯” |
|------|--------|------|
| Spiking Front-End | ~20K | 1.6% |
| Interface + Projection | ~16K | 1.3% |
| Mamba Backbone (4å±‚) | ~1.1M | 91.7% |
| Classification Head | ~65K | 5.4% |
| **æ€»è®¡** | **~1.2M** | **100%** |

### ä¸åŒæ•°æ®é›†é…ç½®

| æ•°æ®é›† | è¾“å…¥å°ºå¯¸ | Spiking Channels | d_model | n_layers | å‚æ•°é‡ |
|--------|---------|------------------|---------|----------|--------|
| N-MNIST | 34Ã—34 | 64 | 128 | 4 | 1.2M |
| DVS Gesture | 128Ã—128 | 128 | 256 | 6 | 8.5M |
| CIFAR10-DVS | 128Ã—128 | 128 | 256 | 6 | 8.5M |

## ğŸ”„ æ•°æ®æµåˆ†æ

### ç»´åº¦å˜åŒ–è¿½è¸ª

```
è¾“å…¥äº‹ä»¶æµ: (32, 300, 2, 34, 34)
    â†“ [Conv+Pool+LIF]
ç¨€ç–è„‰å†²: (32, 300, 64, 8, 8)
    â†“ [Flatten + Smooth]
æ¿€æ´»å‘é‡: (32, 300, 4096)
    â†“ [Linear Projection]
åµŒå…¥åºåˆ—: (32, 300, 128)
    â†“ [4Ã— Mamba Blocks]
å¤„ç†åºåˆ—: (32, 300, 128)
    â†“ [Global Pooling]
èšåˆç‰¹å¾: (32, 128)
    â†“ [LayerNorm + Linear]
è¾“å‡ºlogits: (32, 10)
```

### è®¡ç®—å¤æ‚åº¦

| æ“ä½œ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
|------|-----------|-----------|
| Spiking Front-End | O(TÃ—HÃ—W) | O(BÃ—TÃ—CÃ—HÃ—W) |
| Interface Layer | O(TÃ—F) | O(BÃ—TÃ—F) |
| Mamba Backbone | **O(TÃ—dÂ²)** | O(BÃ—TÃ—d) |
| Classification | O(dÃ—C) | O(BÃ—d) |

**æ³¨æ„**: Mambaçš„çº¿æ€§æ—¶é—´å¤æ‚åº¦ç›¸æ¯”Transformerçš„O(TÂ²Ã—d)æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼

## ğŸ¨ æ¶æ„ç‰¹ç‚¹

### 1. æ··åˆèŒƒå¼
- **å‰ç«¯**: è„‰å†²ç¥ç»ç½‘ç»œ (Event-driven)
- **ä¸»å¹²**: çŠ¶æ€ç©ºé—´æ¨¡å‹ (Continuous)
- **ä¼˜åŠ¿**: ç»“åˆä¸¤è€…ä¼˜ç‚¹

### 2. ç¨€ç–æ€§
- **ç©ºé—´ç¨€ç–**: äº‹ä»¶ç›¸æœºåªè®°å½•å˜åŒ–
- **æ—¶é—´ç¨€ç–**: LIFç¥ç»å…ƒåªåœ¨å¿…è¦æ—¶å‘æ”¾
- **ç»“æœ**: ~78.5% ç¨€ç–ç‡ (DVS Gesture)

### 3. æ•ˆç‡
- **è®¡ç®—**: çº¿æ€§æ—¶é—´å¤æ‚åº¦
- **èƒ½è€—**: ç¨€ç–è„‰å†²é™ä½åŠŸè€—
- **å†…å­˜**: æ¸è¿›å¼å¤„ç†ï¼Œæ— éœ€å…¨å±€æ³¨æ„åŠ›

### 4. æ€§èƒ½
| æ•°æ®é›† | Mamba-Spike | åŸºå‡†SNN | åŸºå‡†ANN |
|--------|-------------|---------|---------|
| N-MNIST | **99.5%** | 98.8% | 99.2% |
| DVS Gesture | **97.8%** | 96.5% | 97.1% |
| CIFAR10-DVS | **92.5%** | 89.6% | 91.8% |

## ğŸ”¬ å…³é”®åˆ›æ–°ç‚¹

### 1. Selective State Spaces
```python
# ä¼ ç»ŸSSM: å‚æ•°å›ºå®š
A, B, C = learnable_parameters()

# Selective SSM: å‚æ•°åŠ¨æ€ï¼ˆä¾èµ–è¾“å…¥ï¼‰
dt, B, C = f(x)  # æ ¹æ®è¾“å…¥è®¡ç®—ï¼
A = -exp(A_log)
```

**ä¸ºä»€ä¹ˆé‡è¦?**
- å¯ä»¥æ ¹æ®å†…å®¹é€‰æ‹©æ€§åœ°è®°ä½æˆ–å¿˜è®°ä¿¡æ¯
- ç±»ä¼¼æ³¨æ„åŠ›æœºåˆ¶ä½†æ›´é«˜æ•ˆ

### 2. Spike-to-Activation Interface
```python
# ä¿æŒæ—¶é—´ä¿¡æ¯
# å°†ç¨€ç–è„‰å†²â†’å¹³æ»‘æ¿€æ´»
# å…è®¸æ¢¯åº¦åå‘ä¼ æ’­
```

**ä¸ºä»€ä¹ˆé‡è¦?**
- æ¡¥æ¥ç¦»æ•£SNNå’Œè¿ç»­Mamba
- ä¿ç•™è„‰å†²çš„æ—¶åºç»“æ„
- å…è®¸ç«¯åˆ°ç«¯è®­ç»ƒ

## ğŸ“š ä»£ç å¯¹åº”å…³ç³»

### æ¶æ„å›¾ â†” ä»£ç 

```python
# models/mamba_spike.py

class MambaSpike(nn.Module):
    def __init__(...):
        # å¯¹åº”å›¾ä¸­çš„ "Spiking Front-End"
        self.spiking_frontend = SpikingFrontEnd(...)

        # å¯¹åº”å›¾ä¸­çš„ "Interface Layer"
        self.spike_to_activation = SpikeToActivation(...)

        # å¯¹åº”å›¾ä¸­çš„ "Input Projection"
        self.input_proj = nn.Linear(spike_features, d_model)

        # å¯¹åº”å›¾ä¸­çš„ "Mamba Backbone"
        self.mamba_blocks = nn.ModuleList([
            MambaBlock(...) for _ in range(n_layers)
        ])

        # å¯¹åº”å›¾ä¸­çš„ "Classification Head"
        self.norm = nn.LayerNorm(d_model)
        self.classifier = nn.Linear(d_model, num_classes)

    def forward(self, x):
        # æŒ‰ç…§æ¶æ„å›¾çš„æµç¨‹
        spikes, _ = self.spiking_frontend(x)
        activations = self.spike_to_activation(spikes)
        x = self.input_proj(activations)

        for block in self.mamba_blocks:
            x = block(x)

        x = x.mean(dim=1)  # Global pooling
        x = self.norm(x)
        logits = self.classifier(x)

        return logits
```

## ğŸ¯ ä½¿ç”¨å»ºè®®

### æŸ¥çœ‹æ¶æ„å›¾æ—¶ï¼š
1. **ä»ä¸Šåˆ°ä¸‹**: è·Ÿéšæ•°æ®æµ
2. **æ³¨æ„é¢œè‰²**: ä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒæ¨¡å—ç±»å‹
3. **æŸ¥çœ‹Legend**: äº†è§£å„ç»„ä»¶å«ä¹‰
4. **è¯»Key Features**: ç†è§£æ ¸å¿ƒåˆ›æ–°

### ä¿®æ”¹æ¶æ„å›¾ï¼š
1. åœ¨draw.ioä¸­æ‰“å¼€
2. å¯ä»¥è°ƒæ•´å¸ƒå±€ã€é¢œè‰²ã€æ–‡å­—
3. æ·»åŠ è‡ªå·±çš„æ³¨é‡Š
4. å¯¼å‡ºä¸ºPNG/PDF/SVG

## ğŸ“– ç›¸å…³æ–‡æ¡£

- `models/mamba_spike.py` - æ¨¡å‹å®ç°ä»£ç 
- `README.md` - é¡¹ç›®å®Œæ•´è¯´æ˜
- è®ºæ–‡: [arXiv:2408.11823](https://arxiv.org/abs/2408.11823)

## ğŸ”— åœ¨çº¿èµ„æº

- [Draw.io å®˜ç½‘](https://app.diagrams.net/)
- [Mamba è®ºæ–‡](https://arxiv.org/abs/2312.00752)
- [snnTorch æ–‡æ¡£](https://snntorch.readthedocs.io/)
