"""
Mamba-Spikeæ¶æ„å±•ç¤ºï¼ˆæ— éœ€å®‰è£…ä¾èµ–ï¼‰
çº¯æ–‡æœ¬å±•ç¤ºæ¨¡å‹æ¶æ„
"""


def print_ascii_architecture():
    """æ‰“å°ASCIIè‰ºæœ¯é£æ ¼çš„æ¶æ„å›¾"""
    print("=" * 80)
    print("Mamba-Spike Architecture Diagram")
    print("=" * 80)
    print()

    diagram = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    Event-based Input                        â”‚
    â”‚                  (B, T, 2, 34, 34)                         â”‚
    â”‚                  DVS Camera Events                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              ğŸ”¥ Spiking Front-End (SNN)                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Conv2d(2â†’32, 3x3) + MaxPool(2x2) + LIF(Î²=0.9)        â”‚  â”‚
    â”‚  â”‚          â†“ Sparse Spikes                              â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                           â–¼                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Conv2d(32â†’32, 3x3) + MaxPool(2x2) + LIF(Î²=0.9)       â”‚  â”‚
    â”‚  â”‚          â†“ Sparse Spikes                              â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                           â–¼                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Conv2d(32â†’64, 3x3) + LIF(Î²=0.9)                      â”‚  â”‚
    â”‚  â”‚          â†“ Sparse Spikes                              â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚         Output: (B, T, 64, H/4, W/4)                       â”‚
    â”‚         Feature: Event-driven, Energy-efficient            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              âš¡ Interface Layer                             â”‚
    â”‚    Spike â†’ Activation Conversion                           â”‚
    â”‚    â€¢ Rate Coding (temporal averaging)                      â”‚
    â”‚    â€¢ Temporal Smoothing (Conv1d, kernel=5)                â”‚
    â”‚         Output: (B, T, 64Ã—H'Ã—W')                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           ğŸ¯ Input Projection                               â”‚
    â”‚         Linear(spike_features â†’ 128)                       â”‚
    â”‚         Output: (B, T, 128)                                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              ğŸ§  Mamba Backbone (SSM)                        â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ ğŸ“¦ Mamba Block 1                                      â”‚  â”‚
    â”‚  â”‚   â”œâ”€ LayerNorm(128)                                   â”‚  â”‚
    â”‚  â”‚   â”œâ”€ SelectiveSSM                                     â”‚  â”‚
    â”‚  â”‚   â”‚   â”œâ”€ Input Projection (d_model â†’ 2Ã—d_inner)      â”‚  â”‚
    â”‚  â”‚   â”‚   â”œâ”€ Conv1d (kernel=4, groups=d_inner)           â”‚  â”‚
    â”‚  â”‚   â”‚   â”œâ”€ State Space Model                           â”‚  â”‚
    â”‚  â”‚   â”‚   â”‚   â€¢ A = -exp(A_log)                          â”‚  â”‚
    â”‚  â”‚   â”‚   â”‚   â€¢ dt, B, C = f(x)  [Data-dependent!]      â”‚  â”‚
    â”‚  â”‚   â”‚   â”‚   â€¢ h[t] = exp(dt*A)*h[t-1] + dt*B*x[t]     â”‚  â”‚
    â”‚  â”‚   â”‚   â”‚   â€¢ y[t] = C*h[t] + D*x[t]                  â”‚  â”‚
    â”‚  â”‚   â”‚   â””â”€ Gated MLP (y * silu(res))                   â”‚  â”‚
    â”‚  â”‚   â””â”€ Residual Connection (+)                          â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ ğŸ“¦ Mamba Block 2 (same structure)                     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ ğŸ“¦ Mamba Block 3 (same structure)                     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ ğŸ“¦ Mamba Block 4 (same structure)                     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                                              â”‚
    â”‚    Feature: O(L) complexity, Long-range modeling            â”‚
    â”‚    Output: (B, T, 128)                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        ğŸ“Š Global Average Pooling                            â”‚
    â”‚           mean over time dimension                          â”‚
    â”‚           Output: (B, 128)                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           ğŸ“ Classification Head                            â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ LayerNorm(128)                                        â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ Linear(128 â†’ num_classes)                            â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  âœ… Output Logits                           â”‚
    â”‚                 (B, num_classes)                            â”‚
    â”‚              Class Predictions                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    print(diagram)
    print("=" * 80)
    print()


def print_model_statistics():
    """æ‰“å°æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
    print("=" * 80)
    print("ğŸ“Š Model Statistics")
    print("=" * 80)
    print()

    stats = """
    Parameter Distribution:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Component                â”‚ Parameters   â”‚ Ratio    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Spiking Front-End        â”‚     ~20K     â”‚   1.6%   â”‚
    â”‚ Interface + Projection   â”‚     ~16K     â”‚   1.3%   â”‚
    â”‚ Mamba Backbone (4 layers)â”‚    ~1.1M     â”‚  91.7%   â”‚
    â”‚ Classification Head      â”‚     ~65K     â”‚   5.4%   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Total                    â”‚    ~1.2M     â”‚  100%    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Configurations for Different Datasets:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Dataset      â”‚ Input     â”‚ Spk_Ch  â”‚ d_model â”‚ Layers â”‚ Params   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ N-MNIST      â”‚  34Ã—34    â”‚   64    â”‚   128   â”‚   4    â”‚  ~1.2M   â”‚
    â”‚ DVS Gesture  â”‚ 128Ã—128   â”‚  128    â”‚   256   â”‚   6    â”‚  ~8.5M   â”‚
    â”‚ CIFAR10-DVS  â”‚ 128Ã—128   â”‚  128    â”‚   256   â”‚   6    â”‚  ~8.5M   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Performance Results (from paper):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Dataset      â”‚ Mamba-Spike  â”‚ Baseline   â”‚ Spikes/    â”‚
    â”‚              â”‚ Accuracy     â”‚ SNN        â”‚ Sample     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ N-MNIST      â”‚   99.5%      â”‚   98.8%    â”‚    -       â”‚
    â”‚ DVS Gesture  â”‚   97.8%      â”‚   96.5%    â”‚   785      â”‚
    â”‚ TIDIGITS     â”‚   99.2%      â”‚   98.3%    â”‚    -       â”‚
    â”‚ CIFAR10-DVS  â”‚   92.5%      â”‚   89.6%    â”‚    -       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    print(stats)
    print("=" * 80)
    print()


def print_key_features():
    """æ‰“å°å…³é”®ç‰¹æ€§"""
    print("=" * 80)
    print("ğŸŒŸ Key Features & Innovations")
    print("=" * 80)
    print()

    features = """
    1. ğŸ”¥ Event-Driven Spiking Front-End
       â€¢ Leaky Integrate-and-Fire (LIF) neurons
       â€¢ Biologically plausible spike generation
       â€¢ Energy-efficient sparse computation
       â€¢ Direct processing of DVS camera events

    2. âš¡ Efficient Spike-to-Activation Interface
       â€¢ Rate coding with temporal averaging
       â€¢ Smooth conversion preserving temporal structure
       â€¢ Enables gradient backpropagation
       â€¢ Bridges discrete SNN and continuous Mamba

    3. ğŸ§  Selective State Space Models (SSM)
       â€¢ Data-dependent parameters: dt, B, C = f(x)
       â€¢ Linear time complexity: O(L) vs O(LÂ²) in Transformers
       â€¢ Long-range temporal dependencies
       â€¢ Selective information retention/forgetting

    4. ğŸ¯ Hybrid Architecture Benefits
       â€¢ Combines SNN efficiency with SSM performance
       â€¢ 78.5% sparsity on DVS Gesture dataset
       â€¢ Lower latency: 15ms vs 18-25ms (baselines)
       â€¢ Higher accuracy across all datasets

    5. ğŸš€ Computational Advantages
       â€¢ Linear-time sequence processing
       â€¢ Reduced memory footprint
       â€¢ GPU-friendly parallel computation
       â€¢ Scalable to long sequences
    """

    print(features)
    print("=" * 80)
    print()


def print_data_flow():
    """æ‰“å°æ•°æ®æµ"""
    print("=" * 80)
    print("ğŸ”„ Data Flow Example (N-MNIST)")
    print("=" * 80)
    print()

    flow = """
    Step-by-Step Dimension Changes:

    Input:
    â””â”€ Event Frames:           (32, 300, 2, 34, 34)
                                 â†“ [B, T, C, H, W]

    Spiking Front-End:
    â”œâ”€ After Conv1 + Pool:     (32, 300, 32, 17, 17)
    â”œâ”€ After Conv2 + Pool:     (32, 300, 32, 8, 8)
    â””â”€ After Conv3:            (32, 300, 64, 8, 8)
                                 â†“ Sparse Spikes

    Interface Layer:
    â”œâ”€ Flatten spatial:        (32, 300, 4096)
    â””â”€ Temporal smooth:        (32, 300, 4096)
                                 â†“ Continuous activations

    Input Projection:
    â””â”€ Linear projection:      (32, 300, 128)
                                 â†“ Embedded sequence

    Mamba Backbone:
    â”œâ”€ After Block 1:          (32, 300, 128)
    â”œâ”€ After Block 2:          (32, 300, 128)
    â”œâ”€ After Block 3:          (32, 300, 128)
    â””â”€ After Block 4:          (32, 300, 128)
                                 â†“ Temporal features

    Global Pooling:
    â””â”€ Mean over time:         (32, 128)
                                 â†“ Aggregated features

    Classification:
    â”œâ”€ LayerNorm:              (32, 128)
    â””â”€ Linear:                 (32, 10)
                                 â†“ Class logits

    Output:
    â””â”€ Predictions:            (32, 10)
                                 [Batch, Classes]
    """

    print(flow)
    print("=" * 80)
    print()


def print_code_mapping():
    """æ‰“å°ä»£ç æ˜ å°„"""
    print("=" * 80)
    print("ğŸ’» Architecture â†’ Code Mapping")
    print("=" * 80)
    print()

    mapping = """
    models/mamba_spike.py:

    class MambaSpike(nn.Module):

        # ğŸ”¥ Spiking Front-End
        self.spiking_frontend = SpikingFrontEnd(
            in_channels=2,
            hidden_channels=32,
            out_channels=64,
            beta=0.9  # LIF decay rate
        )

        # âš¡ Interface Layer
        self.spike_to_activation = SpikeToActivation(
            method="rate"  # Rate coding
        )

        # ğŸ¯ Input Projection
        self.input_proj = nn.Linear(
            spike_features,  # 64 * H' * W'
            d_model          # 128
        )

        # ğŸ§  Mamba Backbone
        self.mamba_blocks = nn.ModuleList([
            MambaBlock(
                d_model=128,
                d_state=16,
                d_conv=4,
                expand=2
            )
            for _ in range(4)  # 4 layers
        ])

        # ğŸ“ Classification Head
        self.norm = nn.LayerNorm(128)
        self.classifier = nn.Linear(128, num_classes)

    Forward Pass:
        spikes, _ = self.spiking_frontend(x)    # Event â†’ Spikes
        activations = self.spike_to_activation(spikes)  # Spikes â†’ Activation
        x = self.input_proj(activations)        # Project to d_model
        for block in self.mamba_blocks:         # Process with SSM
            x = block(x)
        x = x.mean(dim=1)                       # Global pooling
        x = self.norm(x)                        # Normalize
        logits = self.classifier(x)             # Classify
        return logits
    """

    print(mapping)
    print("=" * 80)
    print()


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("ğŸ¨ Mamba-Spike Architecture Visualization")
    print("=" * 80)
    print()

    print_ascii_architecture()
    print_model_statistics()
    print_key_features()
    print_data_flow()
    print_code_mapping()

    print("=" * 80)
    print("ğŸ“š Additional Resources")
    print("=" * 80)
    print()
    print("1. ğŸ“Š Draw.io Diagram:")
    print("   Open 'architecture/mamba_spike_architecture.drawio'")
    print("   in https://app.diagrams.net/")
    print()
    print("2. ğŸ“– Detailed Documentation:")
    print("   Read 'architecture/README.md'")
    print()
    print("3. ğŸ’» Code Implementation:")
    print("   See 'models/mamba_spike.py'")
    print()
    print("4. ğŸ“„ Original Paper:")
    print("   https://arxiv.org/abs/2408.11823")
    print()
    print("=" * 80)
    print()


if __name__ == "__main__":
    main()
